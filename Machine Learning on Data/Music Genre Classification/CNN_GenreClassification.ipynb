{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ea33fc",
   "metadata": {},
   "source": [
    "<h1> A CNN for Genre Classification </h1>\n",
    "\n",
    "Source: https://www.youtube.com/watch?v=dOG-HxpbMSw&list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&index=16\n",
    "\n",
    "Data source: see my GenreClassification.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de05196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e51f3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#load data\n",
    "\n",
    "# split data into training and test\n",
    "\n",
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "        #convert lists into numpy arrays\n",
    "        # x\n",
    "        inputs=np.array(data[\"mfcc\"])\n",
    "        targets=np.array(data[\"labels\"])\n",
    "        return inputs,targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cce464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (4994, 293, 13)\n",
      "Frequency of unique values of the targets:\n",
      "[[  0   1   2   3   4   5   6   7   8   9]\n",
      " [500 500 500 500 499 495 500 500 500 500]]\n"
     ]
    }
   ],
   "source": [
    "inputs,targets = load_data(\"data.json\")\n",
    "#inputs.shape[0] num samples\n",
    "#inputs.shape[1] num time readings\n",
    "#inputs.shape[2] num values per time interval\n",
    "print (\"input shape\", inputs.shape)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(targets, return_counts=True)\n",
    "print(\"Frequency of unique values of the targets:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8948a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2996, 293, 13)\n",
      "(2996, 293, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#create train, validation test sets\n",
    "\n",
    "#build the cnn\n",
    "\n",
    "#compile the network\n",
    "\n",
    "#train the cnn\n",
    "\n",
    "#evaluate the cnn\n",
    "\n",
    "#infer from sample\n",
    "\n",
    "#CNN expects 3d array of input\n",
    "def prepare_datasets(test_size,validation_size,dataset_path):\n",
    "\n",
    "    x,y = load_data(dataset_path)\n",
    "\n",
    "    #test set: test on the fully trained model\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=test_size)\n",
    "    #validation: test on unseen data, but model may end up learning it as we tweak to maximise validation accuracy\n",
    "    x_train,x_validation,y_train,y_validation=train_test_split(x_train,y_train,test_size=validation_size)\n",
    "    print (x_train.shape)\n",
    "    x_train=x_train[...,np.newaxis]\n",
    "    print (x_train.shape)\n",
    "    x_validation=x_validation[...,np.newaxis]\n",
    "    x_test=x_test[...,np.newaxis]\n",
    "    return x_train,x_test,y_train,y_test, x_validation, y_validation\n",
    "    \n",
    "    \n",
    "x_train,x_test,y_train,y_test, x_validation, y_validation = prepare_datasets(0.25,0.2, \"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e6e7e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2996, 293, 13, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(num samples, num intervals, num variables, num channels)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8098fbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 291, 11, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 146, 6, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 146, 6, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 144, 4, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 72, 2, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 72, 2, 32)         128       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 71, 1, 32)         4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 36, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 36, 1, 32)         128       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 88,522\n",
      "Trainable params: 88,330\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model=keras.Sequential()\n",
    "    #CONV LAYER 1\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2), padding='same'))\n",
    "    #Batch normalisation: process that normalises the activations in the current layer for output to the next layer.\n",
    "    #Speeds up training (faster convergence) and reliability.\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    #CONV LAYER 2\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())   \n",
    "    \n",
    "    #CONV LAYER 3\n",
    "    # we shrink the kernal size\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(2,2),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization()) \n",
    "    \n",
    "    #flatten into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))  \n",
    "    \n",
    "    #output layer\n",
    "    #a fully connected layer for classification\n",
    "    NUMBEROFPOSSIBLEOUTPUTS=10\n",
    "    model.add(keras.layers.Dense(NUMBEROFPOSSIBLEOUTPUTS,activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "#each sample has the shape (n,130,13,1) <- (num samples,intervals,variables,channels)\n",
    "input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "model = build_model(input_shape)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2866e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.4326 - accuracy: 0.2336 - val_loss: 2.2701 - val_accuracy: 0.2590\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.8915 - accuracy: 0.3635 - val_loss: 1.7830 - val_accuracy: 0.3632\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6543 - accuracy: 0.4396 - val_loss: 1.5383 - val_accuracy: 0.4633\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5401 - accuracy: 0.4720 - val_loss: 1.4181 - val_accuracy: 0.5140\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4023 - accuracy: 0.5063 - val_loss: 1.3426 - val_accuracy: 0.5274\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3075 - accuracy: 0.5471 - val_loss: 1.3060 - val_accuracy: 0.5381\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2466 - accuracy: 0.5741 - val_loss: 1.2447 - val_accuracy: 0.5554\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 1.1544 - accuracy: 0.5915 - val_loss: 1.1709 - val_accuracy: 0.5995\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 1.0801 - accuracy: 0.6315 - val_loss: 1.1478 - val_accuracy: 0.5968\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 1.0526 - accuracy: 0.6445 - val_loss: 1.1198 - val_accuracy: 0.6075\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0125 - accuracy: 0.6532 - val_loss: 1.0908 - val_accuracy: 0.6142\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.9550 - accuracy: 0.6739 - val_loss: 1.0897 - val_accuracy: 0.6315\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.8831 - accuracy: 0.7003 - val_loss: 1.0568 - val_accuracy: 0.6262\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.8616 - accuracy: 0.7083 - val_loss: 1.0515 - val_accuracy: 0.6342\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.8340 - accuracy: 0.7216 - val_loss: 1.0384 - val_accuracy: 0.6395\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.8044 - accuracy: 0.7160 - val_loss: 1.0337 - val_accuracy: 0.6475\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.7762 - accuracy: 0.7380 - val_loss: 1.0173 - val_accuracy: 0.6315\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.7560 - accuracy: 0.7433 - val_loss: 1.0154 - val_accuracy: 0.6475\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.7198 - accuracy: 0.7557 - val_loss: 0.9714 - val_accuracy: 0.6622\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.6914 - accuracy: 0.7690 - val_loss: 0.9766 - val_accuracy: 0.6689\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.7844 - val_loss: 0.9502 - val_accuracy: 0.6742\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.7877 - val_loss: 1.0150 - val_accuracy: 0.6555\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.8027 - val_loss: 0.9715 - val_accuracy: 0.6609\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.7937 - val_loss: 0.9921 - val_accuracy: 0.6689\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.8141 - val_loss: 0.9412 - val_accuracy: 0.6742\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.8364 - val_loss: 0.9839 - val_accuracy: 0.6702\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.8358 - val_loss: 0.9388 - val_accuracy: 0.6756\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.8438 - val_loss: 0.9408 - val_accuracy: 0.6782\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.8465 - val_loss: 0.9181 - val_accuracy: 0.6809\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.8415 - val_loss: 0.9181 - val_accuracy: 0.6889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b831acd9d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adam is a very very effecting sgd variant for deep learning\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#put all the components together\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_validation,y_validation),epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f033efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0038 - accuracy: 0.6501\n",
      "accuracy on test set is  0.6501200795173645\n"
     ]
    }
   ],
   "source": [
    "#evaluate CNN on test set\n",
    "test_error,test_Accuracy=model.evaluate(x_test,y_test)\n",
    "print (\"accuracy on test set is \", test_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6117b4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
