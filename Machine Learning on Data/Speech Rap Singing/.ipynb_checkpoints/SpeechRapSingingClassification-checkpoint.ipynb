{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d45fcc",
   "metadata": {},
   "source": [
    "<h1>Speech Rap Singing Classification</h1>\n",
    "\n",
    "<b>data source</b>: Provided by Speech Graphics & Rapport, not publicly available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb556c",
   "metadata": {},
   "source": [
    "<h2>Data Preprocesing</h2>\n",
    "<h3>Initial Feature Extraction<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "44c0539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9b8339a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = []\n",
    "#get all filenames associated with each label\n",
    "def extractFileList(_path, _labelLocationInPath):\n",
    "    for i, (currentDir, childDirs, filesInDir) in enumerate(os.walk(PATH)):\n",
    "        for _file in filesInDir:\n",
    "            fullFilePath=os.path.join(currentDir,_file)\n",
    "            dictEntry = {\"path\":fullFilePath,\"label\":currentDir.split('\\\\')[LABELLOCATIONINPATH]}\n",
    "            fileList.append(dictEntry)\n",
    "    return fileList   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "76c6a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMFCCsToFileList(fileList,sr,n_fft,n_mfcc,hop_length):\n",
    "    for _file in fileList:\n",
    "        signal,sr = librosa.load(_file['path'],sr=sr) \n",
    "        mfcc = librosa.feature.mfcc(signal,sr=sr,n_fft=n_fft,n_mfcc=n_mfcc, hop_length = hop_length)\n",
    "        mfcc=mfcc.T\n",
    "        _file['mfcc']=np.array(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "810dada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \".\\\\data\"\n",
    "LABELLOCATIONINPATH=2\n",
    "JSON_PATH=\"data.json\"\n",
    "SAMPLE_RATE = 16000\n",
    "N_MFCC = 13\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH=512\n",
    "NUM_SEGMENTS = 5\n",
    "\n",
    "#get the list of paths and labels\n",
    "fileList=extractFileList(_path=PATH,_labelLocationInPath=LABELLOCATIONINPATH)\n",
    "#add the mfccs for each file\n",
    "addMFCCsToFileList(fileList=fileList,sr=SAMPLE_RATE,n_fft=N_FFT,n_mfcc=N_MFCC,hop_length=HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3ceaf570",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList[0]\n",
    "sr_fileList = pd.Series(fileList)\n",
    "#save our newly created dictionaries in a JSON file for easy retrieval\n",
    "#also transpose them for correct columns\n",
    "np_fileList=np.array(fileList).T\n",
    "sr_fileList = pd.Series(np_fileList)\n",
    "pd.DataFrame.to_json(sr_fileList,path_or_buf=JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f4bf0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       {'path': '.\\data\\rap\\sing002\\sing002_1.wav', '...\n",
      "1       {'path': '.\\data\\rap\\sing002\\sing002_2.wav', '...\n",
      "2       {'path': '.\\data\\rap\\sing002\\sing002_3.wav', '...\n",
      "3       {'path': '.\\data\\rap\\sing002\\sing002_4.wav', '...\n",
      "4       {'path': '.\\data\\rap\\sing002\\sing002_5.wav', '...\n",
      "                              ...                        \n",
      "2875    {'path': '.\\data\\speech\\01g\\01go0317.wav', 'la...\n",
      "2876    {'path': '.\\data\\speech\\01g\\01go0318.wav', 'la...\n",
      "2877    {'path': '.\\data\\speech\\01g\\01go0319.wav', 'la...\n",
      "2878    {'path': '.\\data\\speech\\01g\\01go031a.wav', 'la...\n",
      "2879    {'path': '.\\data\\speech\\01g\\01go031b.wav', 'la...\n",
      "Length: 2880, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in fileList:\n",
    "    #print (len(i['mfcc']))\n",
    "    if len(i['mfcc'])!=94:\n",
    "        print (\"oh no\")\n",
    "print(sr_fileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cebb24",
   "metadata": {},
   "source": [
    "<h3>Further Preprocessing<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "238d8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH=\"data.json\"\n",
    "df_data = pd.read_json(JSON_PATH)\n",
    "\n",
    "#data is initially stored with (x,y) opposite of what we would like\n",
    "df_data=df_data.transpose()\n",
    "\n",
    "#path is used for training\n",
    "df_data=df_data.drop('path',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9e12bd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rap</td>\n",
       "      <td>[[-259.7991333008, 52.0887832642, 14.845832824...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap</td>\n",
       "      <td>[[-51.5158119202, 84.026473999, 13.5537509918,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rap</td>\n",
       "      <td>[[-24.3105449677, 90.9373779297, -54.699748992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rap</td>\n",
       "      <td>[[-218.6664428711, 47.8084869385, 37.528297424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rap</td>\n",
       "      <td>[[-202.5080108643, 117.9148178101, 50.77450180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>speech</td>\n",
       "      <td>[[-278.1077270508, 88.3571166992, -9.653070449...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>speech</td>\n",
       "      <td>[[-271.6434936523, 73.972366333, -1.8853588104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>speech</td>\n",
       "      <td>[[-431.7222290039, 123.4328384399, -15.5955619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>speech</td>\n",
       "      <td>[[-351.3446655273, 134.8014984131, 14.16081047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>speech</td>\n",
       "      <td>[[-397.8897094727, 140.8511505127, -19.8133964...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               mfcc\n",
       "0        rap  [[-259.7991333008, 52.0887832642, 14.845832824...\n",
       "1        rap  [[-51.5158119202, 84.026473999, 13.5537509918,...\n",
       "2        rap  [[-24.3105449677, 90.9373779297, -54.699748992...\n",
       "3        rap  [[-218.6664428711, 47.8084869385, 37.528297424...\n",
       "4        rap  [[-202.5080108643, 117.9148178101, 50.77450180...\n",
       "...      ...                                                ...\n",
       "2875  speech  [[-278.1077270508, 88.3571166992, -9.653070449...\n",
       "2876  speech  [[-271.6434936523, 73.972366333, -1.8853588104...\n",
       "2877  speech  [[-431.7222290039, 123.4328384399, -15.5955619...\n",
       "2878  speech  [[-351.3446655273, 134.8014984131, 14.16081047...\n",
       "2879  speech  [[-397.8897094727, 140.8511505127, -19.8133964...\n",
       "\n",
       "[2880 rows x 2 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b7b446fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_data['mfcc']\n",
    "y=df_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6bd841ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [[-259.7991333008, 52.0887832642, 14.845832824...\n",
      "1       [[-51.5158119202, 84.026473999, 13.5537509918,...\n",
      "2       [[-24.3105449677, 90.9373779297, -54.699748992...\n",
      "3       [[-218.6664428711, 47.8084869385, 37.528297424...\n",
      "4       [[-202.5080108643, 117.9148178101, 50.77450180...\n",
      "                              ...                        \n",
      "2875    [[-278.1077270508, 88.3571166992, -9.653070449...\n",
      "2876    [[-271.6434936523, 73.972366333, -1.8853588104...\n",
      "2877    [[-431.7222290039, 123.4328384399, -15.5955619...\n",
      "2878    [[-351.3446655273, 134.8014984131, 14.16081047...\n",
      "2879    [[-397.8897094727, 140.8511505127, -19.8133964...\n",
      "Name: mfcc, Length: 2880, dtype: object\n",
      "(2880,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f75b4a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          rap\n",
      "1          rap\n",
      "2          rap\n",
      "3          rap\n",
      "4          rap\n",
      "         ...  \n",
      "2875    speech\n",
      "2876    speech\n",
      "2877    speech\n",
      "2878    speech\n",
      "2879    speech\n",
      "Name: label, Length: 2880, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f3aac549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (2592,)\n",
      "x_test (288,)\n",
      "y_train (2592,)\n",
      "y_test (288,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)\n",
    "\n",
    "print (\"x_train\",x_train.shape)\n",
    "print (\"x_test\",x_test.shape)\n",
    "print (\"y_train\",y_train.shape)\n",
    "print (\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0e36c741",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mfcc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-51d5d724d48e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"input shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-210-51d5d724d48e>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#convert lists into numpy arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mfcc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mfcc'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "        #convert lists into numpy arrays\n",
    "        # x\n",
    "        inputs=np.array(data[\"mfcc\"])\n",
    "        targets=np.array(data[\"labels\"])\n",
    "        return inputs,targets\n",
    "inputs,targets = load_data(\"data.json\")\n",
    "print (\"input shape\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351b5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "449da02e",
   "metadata": {},
   "source": [
    "<h1> Traditional Dense Network </h1>\n",
    "    @todo delete this later, it is purely illustrative of why the pure mlp is insufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "adc1691b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-0df305fd8135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#takes multidimensional input and treats it as a vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#mfcc data is mfcc values taken at itervals. Second dimension is values for that interval.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mflattenLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#relu: activation function outputs 0 if net input is less than 0. else outputs h.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#relu is very very effective for training (much faster convergence)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#we will use only a traditional dense mlp for this first test, but CNNs would be far more accurate\n",
    "#takes multidimensional input and treats it as a vector\n",
    "#mfcc data is mfcc values taken at itervals. Second dimension is values for that interval.\n",
    "flattenLayer = keras.layers.Flatten(input_shape=(x.shape[1],x.shape[2]))\n",
    "#relu: activation function outputs 0 if net input is less than 0. else outputs h.\n",
    "#relu is very very effective for training (much faster convergence)\n",
    "# reduced probability of vanishing gradient: derivative of sigmoid can't be higher than 0,25 so it shrinks and becomes tiny\n",
    "# relu does not have this problem. So relu allows us to have much deeper networks\n",
    "#3 hidden layers\n",
    "denseLayer1 = keras.layers.Dense(512,activation=\"relu\")\n",
    "denseLayer2 = keras.layers.Dense(256,activation=\"relu\")\n",
    "denseLayer3 = keras.layers.Dense(64,activation=\"relu\")\n",
    "\n",
    "#we have 10 categories\n",
    "#softmax is an activation function that normalised the output (so total is 1)\n",
    "outputLayer = keras.layers.Dense(10,activation=\"softmax\")\n",
    "model=keras.Sequential([flattenLayer,denseLayer1,denseLayer2,denseLayer3,outputLayer])\n",
    "\n",
    "#Adam is a very very effecting sgd variant for deep learning\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#put all the components together\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"]\n",
    "              )\n",
    "#describe our network\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3761343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the network\n",
    "#batch-size usually 16-128 samples, quick, memory light and fairly accurate\n",
    "#note the very higha ccuract of the test set and low accuracy of the training set (~98% vs ~58%)\n",
    "# we are overfitting\n",
    "model.fit(x_train,y_train, validation_data=(x_test,y_test),epochs=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c7486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0e31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
