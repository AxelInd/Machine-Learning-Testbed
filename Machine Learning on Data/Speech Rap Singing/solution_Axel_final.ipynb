{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1813ff",
   "metadata": {},
   "source": [
    "<h1> Speech Rap Signing Classification</h1>\n",
    "\n",
    "Data source: see my SRS_classifier.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d50b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e518d260",
   "metadata": {},
   "source": [
    "<h2>Data Preperation</h2>\n",
    "First we cycle through the data and interpret the music files as MFCCs. MFCCs and their semantic labels are then stored in a .json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add83052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@param dataset_path: relative location of the dataset.\n",
    "@param json_path:\n",
    "@param n_mfcc: number of mfcc variables to receive\n",
    "@param hop_length: how far along to move the window\n",
    "@param num_segments: how many parts to break each file into\n",
    "\"\"\"\n",
    "def create_mfcc_data(dataset_path, n_mfcc=13, n_fft=2048, hop_length=512, semanticLabelFolderLocation=-2,\n",
    "              num_segments=5, sample_rate=20000,allLabels={\"speech\":1,\"rap\":2,\"singing\":3},duration = 3):\n",
    "    #dictionary to store data\n",
    "    # - mapping: mapp labels to values\n",
    "    # - labels: target\n",
    "    data={\n",
    "        \"mapping\":[],\n",
    "        \"mfcc\":[],\n",
    "        \"labels\":[]\n",
    "    }\n",
    "    #the length of each sample, we know this for this dataset. Could be calculated dynamically\n",
    "    \n",
    "    samples_per_track = sample_rate * duration\n",
    "    #how many data points we expect to appear in each segment we break our track into\n",
    "    num_samples_per_segment = int(samples_per_track/num_segments)\n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment/ hop_length)\n",
    "    \n",
    "    print (\"num_samples_per_segment\",num_samples_per_segment)\n",
    "    #loop through all the genres\n",
    "    #dirpath: folder we are currently in\n",
    "    #dirnames: all the names of the subfolders\n",
    "    #filenames: all the filenames\n",
    "    #i: the count. It MUST be included\n",
    "    #os.walk returns a generator, that creates a tuple of values: \n",
    "    #(current_path, directories in current_path, files in current_path).\n",
    "    # - each iteration is a different genre\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        #ensure we're not yet at the dataset level\n",
    "        if dirpath is not dataset_path:\n",
    "            #save the semantic label (the mappings etc)\n",
    "            #dirpath_components: the individual folder names that make up the full path\n",
    "            dirpath_components = dirpath.split(\"\\\\\") #genre/blues => [\"genre\",\"blues\"]\n",
    "            semantic_label = dirpath_components[semanticLabelFolderLocation]\n",
    "            #use the parent directory of a sound file as its label\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            for f in filenames:\n",
    "                # load audio file : the path of the file is just its directory path plus its name\n",
    "                file_path = os.path.join(dirpath,f)\n",
    "                signal, sr = librosa.load(file_path,sr=sample_rate)\n",
    "                #process segments to extract MFCC and store data\n",
    "                for s in range (0, num_segments):\n",
    "                    start_sample = num_samples_per_segment * s\n",
    "                    finish_sample = start_sample + num_samples_per_segment\n",
    "                    #the mfcc for data points between start_sample and finish_sample\n",
    "                    mfcc = librosa.feature.mfcc(signal[start_sample:finish_sample],sr=sr,n_fft=n_fft,n_mfcc=n_mfcc, hop_length = hop_length)\n",
    "                    mfcc=mfcc.T\n",
    "                    #store mfcc for segement if it has the expected length\n",
    "                    if len(mfcc)==expected_num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        # first iteration was the dataset path\n",
    "                        correctLabel = allLabels[semantic_label]\n",
    "                        data[\"labels\"].append(correctLabel)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc_data(data,json_path):\n",
    "    #save what we have created as a jason file\n",
    "    with open(json_path,\"w\") as fp:\n",
    "        json.dump(data,fp,indent=4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08bbf7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We use the same MFCC data drawn at 16000 samples per second as we generated for the multi-layer perceptron approach used previously (see SRS_classifier.ipynb).\n",
    "\n",
    "Data structure:\n",
    "\n",
    "$x.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables})$\n",
    "\n",
    "$x_i.\\texttt{shape} = (\\text{num time intervals}, \\text{num mfcc variables}))$\n",
    "\n",
    "\n",
    "$y.\\texttt{shape}=(\\text{num labels})$\n",
    "\n",
    "$y_i=\\text{label}$\n",
    "\n",
    "where $\\text{label} \\in \\{1,2,3\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b608c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from the file\n",
    "#split data into training and test\n",
    "\"\"\"\n",
    "load data from a json file with objects \"mfcc\" and \"labels\"\n",
    "@param dataset_path: path to the json file\n",
    "@return np array of mfcc data, np array of target values\n",
    "\"\"\"\n",
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "        inputs=np.array(data[\"mfcc\"])\n",
    "        targets=np.array(data[\"labels\"])\n",
    "        return inputs,targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb1594",
   "metadata": {},
   "source": [
    "<h3>Load the data</h3>\n",
    "Load the data from the jason file and verify that the inputs are of the expected type, and the sample size is as expected, in this case: 480 samples of each label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_data(\"data.json\")\n",
    "print (\"input shape\", x.shape)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y, return_counts=True)\n",
    "print(\"Frequency of unique values of the targets:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5765372",
   "metadata": {},
   "source": [
    "<h3>Create training, validation and test datasets</h3>\n",
    "<ul>\n",
    "    <li><b>training</b>: used to train the model.</li>\n",
    "    <li><b>validation</b>: used to evaluate the model after training.</li>\n",
    "    <li><b>test</b>: used to evaluate a model that does well on validation. Ensures that the ML engineer has not been inadvertantly tweaking his model to work on the validation set alone, rather than generalising.</li>\n",
    "    </ul>\n",
    "    \n",
    "Here we also add another axis/dimension to our input, giving each training sample a channel depth of 1. (Our CNN will require 3D samples as input). Our labels do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def prepare_datasets(x,y,test_size,validation_size,dataset_path):\n",
    "    #test set: test on the fully trained model\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=test_size)\n",
    "    #validation: test on unseen data, but model may end up learning it as we tweak to maximise validation accuracy\n",
    "    x_train,x_validation,y_train,y_validation=train_test_split(x_train,y_train,test_size=validation_size)\n",
    "    x_train=x_train[...,np.newaxis]\n",
    "    x_validation=x_validation[...,np.newaxis]\n",
    "    x_test=x_test[...,np.newaxis]\n",
    "    return x_train,x_test,y_train,y_test, x_validation, y_validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442ec35",
   "metadata": {},
   "source": [
    "Data structure:\n",
    "\n",
    "$x_{train}.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables},\\text{depth})$\n",
    "\n",
    "$x_{validate}.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables},\\text{depth})$\n",
    "\n",
    "$x_{test}.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables},\\text{depth})$\n",
    "\n",
    "\n",
    "\n",
    "Where $\\text{depth}=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6343c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test, x_validation, y_validation = prepare_datasets(x,y,0.25,0.2, \"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be15f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(num samples, num intervals, num variables, num channels)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3cb0ea",
   "metadata": {},
   "source": [
    "<h2>Models</h2>\n",
    "<h3>Model Design 1: Convolutional Neural Network</h3>\n",
    "For this model, I opt for a traditional CNN design: three pooled convolutional layers, followed by a single fully connected layer and an output layer, implemented in Tensorflow's Keras environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\"\"\"\n",
    "Creates a model of three pooled convolutional layers, followed by a single fully connected layer and an output layer.\n",
    "@param input_shape: the structure of SINGLE value x_i (omits the first dimension of x which is the total number of samples.)\n",
    "@return uncompiled keras model of the CNN.\n",
    "\"\"\"\n",
    "def build_model_cnn(input_shape,dropout_rate=0):\n",
    "    model=keras.Sequential()\n",
    "    #CONV LAYER 1\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2), padding='same'))\n",
    "    #Batch normalisation: process that normalises the activations in the current layer for output to the next layer.\n",
    "    #Speeds up training (faster convergence) and reliability.\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    #CONV LAYER 2\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())   \n",
    "\n",
    "    #CONV LAYER 3\n",
    "    # we shrink the kernal size\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(2,2),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization()) \n",
    "\n",
    "    #flatten into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(dropout_rate))  \n",
    "    \n",
    "    #output layer\n",
    "    #a fully connected layer for classification\n",
    "    NUMBEROFPOSSIBLEOUTPUTS=4\n",
    "    model.add(keras.layers.Dense(NUMBEROFPOSSIBLEOUTPUTS,activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each sample has the shape (n,130,13,1) <- (num samples,intervals,variables,channels)\n",
    "input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "model_cnn = build_model_cnn(input_shape,dropout_rate=0.4)\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2986b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam is a very very effecting sgd variant for deep learning\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#put all the components together\n",
    "model_cnn.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c082a0",
   "metadata": {},
   "source": [
    "<h3>Model Design 2: Dense Neural Netowrk</h3>\n",
    "For this model, I opt for a traditional MLP design: three hidden convolutional layers and an output layer, implemented in Tensorflow's Keras environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88691be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_dense(input_shape,dropout_rate=0):\n",
    "    model=keras.Sequential()\n",
    "    #Flatten Layer\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    #Dense Layer 1\n",
    "    model.add(keras.layers.Dense(512,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "    #Dense Layer 2\n",
    "    model.add(keras.layers.Dense(256,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(dropout_rate))              \n",
    "    #Dense Layer 3\n",
    "    model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "    #Output Layer\n",
    "    NUMOUTPUTS=4\n",
    "    model.add(keras.layers.Dense(NUMOUTPUTS,activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953829ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_dense=(x.shape[1],x.shape[2])\n",
    "model_dense = build_model_dense(input_shape=input_shape, dropout_rate=0.1)\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6913d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam is a very very effecting sgd variant for deep learning\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#put all the components together\n",
    "model_dense.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d179e37",
   "metadata": {},
   "source": [
    "<h3>Model Design 3: Long Short Term Memory</h3>\n",
    "For this model, I opt for a two-deep LTSM followed by a dense and output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a model of two pooled LSTM nodes. These are unwrapped and used to learn predictive state information.\n",
    "\"\"\"\n",
    "def build_model_lstm(input_shape,dropoutRate=0):\n",
    "    model=keras.Sequential()\n",
    "    \n",
    "    #LSTM Layer 1\n",
    "    #return_sequences = True: sequence to sequence layer, otherwise sequence to vector\n",
    "    model.add(keras.layers.LSTM(units=64,activation='tanh',input_shape=input_shape,return_sequences=True))\n",
    "    #LSTM Layer 2\n",
    "    model.add(keras.layers.LSTM(units=64,activation='tanh',input_shape=input_shape,return_sequences=False))\n",
    "    \n",
    "    #pipe output into a dense layer. No need to flatten because sequence to vector\n",
    "    model.add(keras.layers.Dense(units=64,activation='relu'))\n",
    "    model.add(keras.layers.Dropout(dropoutRate))\n",
    "    \n",
    "    #output layer\n",
    "    #a fully connected layer for classification\n",
    "    NUMBEROFPOSSIBLEOUTPUTS=4\n",
    "    model.add(keras.layers.Dense(NUMBEROFPOSSIBLEOUTPUTS,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each sample has the shape (num samples,intervals,variables,channels=1)\n",
    "input_shape=(x_train.shape[1], x_train.shape[2])\n",
    "model_lstm = build_model_lstm(input_shape,dropoutRate=0.4)\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam is a very very effecting sgd variant for deep learning\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#put all the components together\n",
    "model_lstm.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e95e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b8c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51f8e779",
   "metadata": {},
   "source": [
    "<h3>Compiling the model</h3>\n",
    "<ul><b>Optimizer</b>: Adam</ul>\n",
    "<ul><b>Loss Function</b>: sparse_categorical_crossentropy - a powerful tool for categorization tasks.</ul>\n",
    "<ul><b>Metrics</b>: accuracy</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf69a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaefd903",
   "metadata": {},
   "source": [
    "<h2>Training the Models</h2>\n",
    "We fit the model to our training data and validate it against our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores the progression of several metrics as the model trains.\n",
    "import time\n",
    "startTime = time.perf_counter()\n",
    "history_cnn = model_cnn.fit(x_train,y_train,validation_data=(x_validation,y_validation),epochs=50)\n",
    "endTime = time.perf_counter()\n",
    "print (\"Run Complete. Time taken:\",endTime-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "startTime = time.perf_counter()\n",
    "history_dense = model_dense.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=50, batch_size=32)\n",
    "endTime = time.perf_counter()\n",
    "print (\"Run Complete. Time taken:\",endTime-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9143fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.1)\n",
    "\n",
    "import time\n",
    "startTime = time.perf_counter()\n",
    "history_lstm = model_lstm.fit(x_train,y_train,validation_data=(x_validation,y_validation),epochs=50)\n",
    "endTime = time.perf_counter()\n",
    "print (\"Run Complete. Time taken:\",endTime-startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cd653",
   "metadata": {},
   "source": [
    "<h2>Evaluating the Trained Model</h2>\n",
    "We plot the history of the model across epochs with respect to accuracy and error using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fcee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80ae58",
   "metadata": {},
   "source": [
    "It is clear that the model has trained well and consistently achieves accuracy above $97 \\%$ on the validation set. It seems to converge to this value after about 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_histories(histories, labels):\n",
    "    fig,axs = plt.subplots(2,2,figsize=(15,7))\n",
    "    \n",
    "    pos=0\n",
    "    for history in histories:\n",
    "        axs[0,0].plot(history.history[\"accuracy\"],label=\"train accuracy {}\".format((labels[pos])))\n",
    "        pos=pos+1\n",
    "    #loc sets location\n",
    "    #axs[0,0].legend(loc=\"lower right\")\n",
    "    axs[0,0].set_title(\"Training Accuracy Evaluation\")\n",
    "    axs[0,0].set_ylabel(\"accuracy\")\n",
    "    axs[0,0].set_xlabel(\"epoch\")\n",
    "    pos=0\n",
    "    \n",
    "    for history in histories:\n",
    "        axs[0,1].plot(history.history[\"val_accuracy\"],label=\"test accuracy {}\".format(labels[pos]))\n",
    "        #loc sets location\n",
    "        pos=pos+1\n",
    "    #axs[0,1].legend(loc=\"lower right\")\n",
    "    axs[0,1].set_title(\"Test Accuracy Evaluation\")\n",
    "    axs[0,1].set_ylabel(\"accuracy\")\n",
    "    axs[0,1].set_xlabel(\"epoch\")   \n",
    "    pos=0\n",
    "    \n",
    "    for history in histories:\n",
    "        axs[1,0].plot(history.history[\"loss\"],label=\"train error {}\".format(labels[pos]))\n",
    "        pos=pos+1\n",
    "    axs[1,0].set_ylabel(\"error\")\n",
    "    #loc sets location\n",
    "    #axs[1,0].legend(loc=\"lower right\")\n",
    "    axs[1,0].set_title(\"Training Error Evaluation\")\n",
    "    axs[1,0].set_xlabel(\"epoch\")\n",
    "        \n",
    "    pos=0\n",
    "    for history in histories:\n",
    "        #axs[1,1].plot(history.history[\"val_loss\"],label=\"test error {}\".format(labels[pos]))\n",
    "        axs[1,1].plot(history.history[\"val_loss\"],label=\"{}\".format(labels[pos]))\n",
    "        pos=pos+1\n",
    "    axs[1,1].set_ylabel(\"error\")\n",
    "    #loc sets location\n",
    "    axs[1,1].legend(bbox_to_anchor=(0.75, -1),loc=\"lower right\")\n",
    "    axs[1,1].set_title(\"Test Error Evaluation\")\n",
    "    axs[1,1].set_xlabel(\"error\")\n",
    "    axs[1,1].set_xlabel(\"epoch\")\n",
    "    #just keeps the images from overlapping\n",
    "    fig.tight_layout() \n",
    "    #plt.show()\n",
    "    plt.savefig('accuracyMeasures.png')\n",
    "\n",
    "plot_accuracy_histories([history_cnn,history_dense,history_lstm],labels=[\"Convolutional Neural Network\",\"Dense MLP\",\"Long Short Term Memory\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
