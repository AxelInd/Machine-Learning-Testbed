{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1813ff",
   "metadata": {},
   "source": [
    "<h1> Speech Rap Signing Classification</h1>\n",
    "\n",
    "Source: https://www.youtube.com/watch?v=dOG-HxpbMSw&list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&index=16\n",
    "\n",
    "Data source: see my SRS_classifier.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d50b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08bbf7",
   "metadata": {},
   "source": [
    "<h2>Data Preperation</h2>\n",
    "\n",
    "We use the same MFCC data drawn at 16000 samples per second as we generated for the multi-layer perceptron approach used previously (see SRS_classifier.ipynb).\n",
    "\n",
    "Data structure:\n",
    "\n",
    "$x.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables})$\n",
    "\n",
    "$x_i.\\texttt{shape} = (\\text{num time intervals}, \\text{num mfcc variables}))$\n",
    "\n",
    "\n",
    "$y.\\texttt{shape}=(\\text{num labels})$\n",
    "\n",
    "$y_i=\\text{label}$\n",
    "\n",
    "where $\\text{label} \\in \\{1,2,3\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b608c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from the file\n",
    "#split data into training and test\n",
    "\"\"\"\n",
    "load data from a json file with objects \"mfcc\" and \"labels\"\n",
    "@param dataset_path: path to the json file\n",
    "@return np array of mfcc data, np array of target values\n",
    "\"\"\"\n",
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "        inputs=np.array(data[\"mfcc\"])\n",
    "        targets=np.array(data[\"labels\"])\n",
    "        return inputs,targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb1594",
   "metadata": {},
   "source": [
    "<h3>Load the data</h3>\n",
    "Load the data from the jason file and verify that the inputs are of the expected type, and the sample size is as expected, in this case: 480 samples of each label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232f9eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (1440, 94, 13)\n",
      "Frequency of unique values of the targets:\n",
      "[[  1   2   3]\n",
      " [480 480 480]]\n"
     ]
    }
   ],
   "source": [
    "x,y = load_data(\"data.json\")\n",
    "print (\"input shape\", x.shape)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y, return_counts=True)\n",
    "print(\"Frequency of unique values of the targets:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5765372",
   "metadata": {},
   "source": [
    "<h3>Create training, validation and test datasets</h3>\n",
    "<ul>\n",
    "    <li><b>training</b>: used to train the model.</li>\n",
    "    <li><b>validation</b>: used to evaluate the model after training.</li>\n",
    "    <li><b>test</b>: used to evaluate a model that does well on validation. Ensures that the ML engineer has not been inadvertantly tweaking his model to work on the validation set alone, rather than generalising.</li>\n",
    "    </ul>\n",
    "    \n",
    "Here we also add another axis/dimension to our input, giving each training sample a channel depth of 1. (Our CNN will require 3D samples as input). Our labels do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac8ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def prepare_datasets(x,y,test_size,validation_size,dataset_path):\n",
    "    #test set: test on the fully trained model\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=test_size)\n",
    "    #validation: test on unseen data, but model may end up learning it as we tweak to maximise validation accuracy\n",
    "    x_train,x_validation,y_train,y_validation=train_test_split(x_train,y_train,test_size=validation_size)\n",
    "    x_train=x_train[...,np.newaxis]\n",
    "    x_validation=x_validation[...,np.newaxis]\n",
    "    x_test=x_test[...,np.newaxis]\n",
    "    return x_train,x_test,y_train,y_test, x_validation, y_validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442ec35",
   "metadata": {},
   "source": [
    "Data structure:\n",
    "\n",
    "$x_{train}.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables},\\text{depth})$\n",
    "\n",
    "$x_{validate}.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables},\\text{depth})$\n",
    "\n",
    "$x_{test}.\\texttt{shape}=(\\text{num samples},\\text{num time intervals}, \\text{num MFCC variables},\\text{depth})$\n",
    "\n",
    "\n",
    "\n",
    "Where $\\text{depth}=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6343c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test, x_validation, y_validation = prepare_datasets(x,y,0.25,0.2, \"data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be15f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 94, 13, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(num samples, num intervals, num variables, num channels)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3cb0ea",
   "metadata": {},
   "source": [
    "<h2>Model Design</h2>\n",
    "For this model, I opt for a traditional CNN design: three pooled convolutional layers, followed by a single fully connected layer and an output layer, implemented in Tensorflow's Keras environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943d6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\"\"\"\n",
    "Creates a model of three pooled convolutional layers, followed by a single fully connected layer and an output layer.\n",
    "@param input_shape: the structure of SINGLE value x_i (omits the first dimension of x which is the total number of samples.)\n",
    "@return uncompiled keras model of the CNN.\n",
    "\"\"\"\n",
    "def build_model(input_shape,dropoutRate=0):\n",
    "    model=keras.Sequential()\n",
    "    #CONV LAYER 1\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2), padding='same'))\n",
    "    #Batch normalisation: process that normalises the activations in the current layer for output to the next layer.\n",
    "    #Speeds up training (faster convergence) and reliability.\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    #CONV LAYER 2\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())   \n",
    "\n",
    "    #CONV LAYER 3\n",
    "    # we shrink the kernal size\n",
    "    model.add(keras.layers.Conv2D(filters=32,kernel_size=(2,2),activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization()) \n",
    "\n",
    "    #flatten into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(dropoutRate))  \n",
    "    \n",
    "    #output layer\n",
    "    #a fully connected layer for classification\n",
    "    NUMBEROFPOSSIBLEOUTPUTS=4\n",
    "    model.add(keras.layers.Dense(NUMBEROFPOSSIBLEOUTPUTS,activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ef1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each sample has the shape (n,130,13,1) <- (num samples,intervals,variables,channels)\n",
    "input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "model = build_model(input_shape,dropoutRate=0.4)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8e779",
   "metadata": {},
   "source": [
    "<h3>Compiling the model</h3>\n",
    "<ul><b>Optimizer</b>: Adam</ul>\n",
    "<ul><b>Loss Function</b>: sparse_categorical_crossentropy - a powerful tool for categorization tasks.</ul>\n",
    "<ul><b>Metrics</b>: accuracy</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam is a very very effecting sgd variant for deep learning\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#put all the components together\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"]\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaefd903",
   "metadata": {},
   "source": [
    "<h2>Training the Model</h2>\n",
    "We fit the model to our training data and validate it against our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores the progression of several metrics as the model trains.\n",
    "history = model.fit(x_train,y_train,validation_data=(x_validation,y_validation),epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9cd653",
   "metadata": {},
   "source": [
    "<h2>Evaluating the Trained Model</h2>\n",
    "We plot the history of the model across epochs with respect to accuracy and error using the $\\texttt{plot_history(...)}$ function provided by Valerio Velardo in \n",
    "\n",
    "https://www.youtube.com/watch?v=_xcFAiufwd0&list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&index=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3fcee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "https://www.youtube.com/watch?v=_xcFAiufwd0&list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf&index=13\n",
    "Plot the history of the model across epochs with respect to accuracy and error as two subplots.\n",
    "@param history: a history produced by a model.fit function of a keras model.\n",
    "\"\"\"\n",
    "def plot_history(history):\n",
    "    fig,axs = plt.subplots(2)\n",
    "    axs[0].plot(history.history[\"accuracy\"],label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"],label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"accuracy\")\n",
    "    #loc sets location\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"accuracy eval\")\n",
    "    \n",
    "    axs[1].plot(history.history[\"loss\"],label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"],label=\"test error\")\n",
    "    axs[1].set_ylabel(\"error\")\n",
    "    #loc sets location\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"error eval\")\n",
    "    axs[1].set_xlabel(\"error\")\n",
    "    axs[1].set_xlabel(\"epoch\")\n",
    "    \n",
    "    #just keeps the images from overlapping\n",
    "    fig.tight_layout() \n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80ae58",
   "metadata": {},
   "source": [
    "It is clear that the model has trained well and consistently achieves accuracy above $97 \\%$ on the validation set. It seems to converge to this value after about 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "810988c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e634d",
   "metadata": {},
   "source": [
    "A simple prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d80927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "see whether the model makes  the correct prediction about a sample\n",
    "@param x_n: the input mfcc data\n",
    "@param y_n: the true label of the data\n",
    "@param cats: the text representation of the output categories\n",
    "@return a string describing the prediction and the actual label of x_n\n",
    "\"\"\"\n",
    "def predict(x_n, y_n,cats):\n",
    "    #predict expects a batch of values as input.\n",
    "    # it should be the first value in x_n.shape\n",
    "    x_n=x_n[np.newaxis,...]\n",
    "    prediction = np.argmax(model.predict(x_n))\n",
    "    predictionAsString=cats[prediction-1]\n",
    "    textPrediction = \"We predict:{}\\nActual answer is:{}\".format(predictionAsString,cats[y_n-1])\n",
    "    return textPrediction\n",
    "sampleNum = int(np.random.rand()*x_test.shape[0])\n",
    "print (\"Testing Sample Number \",sampleNum)\n",
    "x_n=x_test[sampleNum]\n",
    "y_n=y_test[sampleNum]\n",
    "\n",
    "cats =  ['speech','rap','singing','failure']\n",
    "print(predict(x_n,y_n,cats))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b48bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c56e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece205a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b370db67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-888eae621f0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m66\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"sequential\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    211\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[0;32m    651\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0;32m    652\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2516\u001b[1;33m     return list(_generate_zero_filled_state_for_cell(\n\u001b[0m\u001b[0;32m   2517\u001b[0m         self, inputs, batch_size, dtype))\n\u001b[0;32m   2518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2996\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2998\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3014\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3015\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3016\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   3009\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3010\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3011\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2911\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2912\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2958\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2960\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2961\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2894\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2895\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2896\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2897\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3028\u001b[0m     \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m     \"\"\"\n\u001b[1;32m-> 3030\u001b[1;33m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[0;32m   3031\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   3032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m    868\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd766e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
